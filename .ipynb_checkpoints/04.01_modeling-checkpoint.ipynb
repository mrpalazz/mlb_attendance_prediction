{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./prepared_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57444 entries, 0 to 57443\n",
      "Data columns (total 99 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   rank                       57444 non-null  int32  \n",
      " 1   attendance                 57444 non-null  float64\n",
      " 2   cLI                        57444 non-null  float64\n",
      " 3   streak                     57444 non-null  int64  \n",
      " 4   year                       57444 non-null  int64  \n",
      " 5   num-date                   57444 non-null  int32  \n",
      " 6   wins                       57444 non-null  int64  \n",
      " 7   losses                     57444 non-null  int64  \n",
      " 8   Capacity                   57444 non-null  int32  \n",
      " 9   dist_to_center_field_feet  57444 non-null  int32  \n",
      " 10  roof_type_Fixed            57444 non-null  uint8  \n",
      " 11  roof_type_Open             57444 non-null  uint8  \n",
      " 12  roof_type_Retractable      57444 non-null  uint8  \n",
      " 13  type_Contemporary          57444 non-null  uint8  \n",
      " 14  type_Jewel box             57444 non-null  uint8  \n",
      " 15  type_Modern                57444 non-null  uint8  \n",
      " 16  type_Multipurpose          57444 non-null  uint8  \n",
      " 17  type_Retro-classic         57444 non-null  uint8  \n",
      " 18  type_Retro-modern          57444 non-null  uint8  \n",
      " 19  Surface_Artificial turf    57444 non-null  uint8  \n",
      " 20  Surface_Grass              57444 non-null  uint8  \n",
      " 21  day_night_D                57444 non-null  uint8  \n",
      " 22  day_night_N                57444 non-null  uint8  \n",
      " 23  month_Apr                  57444 non-null  uint8  \n",
      " 24  month_Aug                  57444 non-null  uint8  \n",
      " 25  month_Jul                  57444 non-null  uint8  \n",
      " 26  month_Jun                  57444 non-null  uint8  \n",
      " 27  month_Mar                  57444 non-null  uint8  \n",
      " 28  month_May                  57444 non-null  uint8  \n",
      " 29  month_Oct                  57444 non-null  uint8  \n",
      " 30  month_Sep                  57444 non-null  uint8  \n",
      " 31  day_Friday                 57444 non-null  uint8  \n",
      " 32  day_Monday                 57444 non-null  uint8  \n",
      " 33  day_Saturday               57444 non-null  uint8  \n",
      " 34  day_Sunday                 57444 non-null  uint8  \n",
      " 35  day_Thursday               57444 non-null  uint8  \n",
      " 36  day_Tuesday                57444 non-null  uint8  \n",
      " 37  day_Wednesday              57444 non-null  uint8  \n",
      " 38  opponent_ARI               57444 non-null  uint8  \n",
      " 39  opponent_ATL               57444 non-null  uint8  \n",
      " 40  opponent_BAL               57444 non-null  uint8  \n",
      " 41  opponent_BOS               57444 non-null  uint8  \n",
      " 42  opponent_CHC               57444 non-null  uint8  \n",
      " 43  opponent_CHW               57444 non-null  uint8  \n",
      " 44  opponent_CIN               57444 non-null  uint8  \n",
      " 45  opponent_CLE               57444 non-null  uint8  \n",
      " 46  opponent_COL               57444 non-null  uint8  \n",
      " 47  opponent_DET               57444 non-null  uint8  \n",
      " 48  opponent_FLA               57444 non-null  uint8  \n",
      " 49  opponent_HOU               57444 non-null  uint8  \n",
      " 50  opponent_KCR               57444 non-null  uint8  \n",
      " 51  opponent_LAA               57444 non-null  uint8  \n",
      " 52  opponent_LAD               57444 non-null  uint8  \n",
      " 53  opponent_MIA               57444 non-null  uint8  \n",
      " 54  opponent_MIL               57444 non-null  uint8  \n",
      " 55  opponent_MIN               57444 non-null  uint8  \n",
      " 56  opponent_NYM               57444 non-null  uint8  \n",
      " 57  opponent_NYY               57444 non-null  uint8  \n",
      " 58  opponent_OAK               57444 non-null  uint8  \n",
      " 59  opponent_PHI               57444 non-null  uint8  \n",
      " 60  opponent_PIT               57444 non-null  uint8  \n",
      " 61  opponent_SDP               57444 non-null  uint8  \n",
      " 62  opponent_SEA               57444 non-null  uint8  \n",
      " 63  opponent_SFG               57444 non-null  uint8  \n",
      " 64  opponent_STL               57444 non-null  uint8  \n",
      " 65  opponent_TBR               57444 non-null  uint8  \n",
      " 66  opponent_TEX               57444 non-null  uint8  \n",
      " 67  opponent_TOR               57444 non-null  uint8  \n",
      " 68  opponent_WSN               57444 non-null  uint8  \n",
      " 69  home_team_ARI              57444 non-null  uint8  \n",
      " 70  home_team_ATL              57444 non-null  uint8  \n",
      " 71  home_team_BAL              57444 non-null  uint8  \n",
      " 72  home_team_BOS              57444 non-null  uint8  \n",
      " 73  home_team_CHC              57444 non-null  uint8  \n",
      " 74  home_team_CHW              57444 non-null  uint8  \n",
      " 75  home_team_CIN              57444 non-null  uint8  \n",
      " 76  home_team_CLE              57444 non-null  uint8  \n",
      " 77  home_team_COL              57444 non-null  uint8  \n",
      " 78  home_team_DET              57444 non-null  uint8  \n",
      " 79  home_team_HOU              57444 non-null  uint8  \n",
      " 80  home_team_KCR              57444 non-null  uint8  \n",
      " 81  home_team_LAA              57444 non-null  uint8  \n",
      " 82  home_team_LAD              57444 non-null  uint8  \n",
      " 83  home_team_MIA              57444 non-null  uint8  \n",
      " 84  home_team_MIL              57444 non-null  uint8  \n",
      " 85  home_team_MIN              57444 non-null  uint8  \n",
      " 86  home_team_NYM              57444 non-null  uint8  \n",
      " 87  home_team_NYY              57444 non-null  uint8  \n",
      " 88  home_team_OAK              57444 non-null  uint8  \n",
      " 89  home_team_PHI              57444 non-null  uint8  \n",
      " 90  home_team_PIT              57444 non-null  uint8  \n",
      " 91  home_team_SDP              57444 non-null  uint8  \n",
      " 92  home_team_SEA              57444 non-null  uint8  \n",
      " 93  home_team_SFG              57444 non-null  uint8  \n",
      " 94  home_team_STL              57444 non-null  uint8  \n",
      " 95  home_team_TBR              57444 non-null  uint8  \n",
      " 96  home_team_TEX              57444 non-null  uint8  \n",
      " 97  home_team_TOR              57444 non-null  uint8  \n",
      " 98  home_team_WSN              57444 non-null  uint8  \n",
      "dtypes: float64(2), int32(4), int64(4), uint8(89)\n",
      "memory usage: 8.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>attendance</th>\n",
       "      <th>cLI</th>\n",
       "      <th>streak</th>\n",
       "      <th>year</th>\n",
       "      <th>num-date</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>Capacity</th>\n",
       "      <th>dist_to_center_field_feet</th>\n",
       "      <th>...</th>\n",
       "      <th>home_team_PHI</th>\n",
       "      <th>home_team_PIT</th>\n",
       "      <th>home_team_SDP</th>\n",
       "      <th>home_team_SEA</th>\n",
       "      <th>home_team_SFG</th>\n",
       "      <th>home_team_STL</th>\n",
       "      <th>home_team_TBR</th>\n",
       "      <th>home_team_TEX</th>\n",
       "      <th>home_team_TOR</th>\n",
       "      <th>home_team_WSN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>15117.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41922</td>\n",
       "      <td>408</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>45996.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45494</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>44054.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41265</td>\n",
       "      <td>391</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>44054.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>56000</td>\n",
       "      <td>395</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20825.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40209</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  attendance   cLI  streak  year  num-date  wins  losses  Capacity  \\\n",
       "0     2     15117.0  1.16      -1  2008         1     1       1     41922   \n",
       "1     3     45996.0  0.96      -1  2008         1     0       1     45494   \n",
       "2     5     44054.0  1.00      -2  2008         1     0       2     41265   \n",
       "3     1     44054.0  1.09       2  2008         1     2       0     56000   \n",
       "4     1     20825.0  0.99       2  2008         1     2       0     40209   \n",
       "\n",
       "   dist_to_center_field_feet  ...  home_team_PHI  home_team_PIT  \\\n",
       "0                        408  ...              0              0   \n",
       "1                        400  ...              0              0   \n",
       "2                        391  ...              0              0   \n",
       "3                        395  ...              0              0   \n",
       "4                        396  ...              0              0   \n",
       "\n",
       "   home_team_SDP  home_team_SEA  home_team_SFG  home_team_STL  home_team_TBR  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              1              0   \n",
       "2              0              0              1              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              1              0              0              0              0   \n",
       "\n",
       "   home_team_TEX  home_team_TOR  home_team_WSN  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              0              0              0  \n",
       "4              0              0              0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.isnull().sum()\n",
    "df.dropna(subset = [\"attendance\"], inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000e+00 2.0825e+04 9.9000e-01 2.0000e+00 2.0080e+03 1.0000e+00\n",
      " 2.0000e+00 0.0000e+00 4.0209e+04 3.9600e+02 0.0000e+00 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 1.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 1.0000e+00 1.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00]\n"
     ]
    }
   ],
   "source": [
    "y = df.attendance\n",
    "X = df.drop(columns = \"attendance\")\n",
    "print(np.array(df.iloc[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the Training done with Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:int(X.shape[0]*0.7)]\n",
    "X_test = X[int(X.shape[0]*0.7):]\n",
    "y_train = y[:int(X.shape[0]*0.7)]\n",
    "y_test = y[int(X.shape[0]*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = regr,\n",
    "\n",
    "param_distributions = random_grid,\n",
    "               n_iter = 10, cv = 5, verbose=2, random_state=35, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=8, n_estimators=1000, random_state=0, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor(n_estimators=1000, max_depth=8, random_state=0, verbose=1)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2646929421446811"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.predict(X_test)\n",
    "regr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Create KFold cross-validation object\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "\n",
    "# Iterate through CV splits\n",
    "results = []\n",
    "for tr, tt in cv.split(X, y):\n",
    "    # Fit the model on training data\n",
    "    regr.fit(X.iloc[tr], y.iloc[tr])\n",
    "    \n",
    "    # Generate predictions on the test data and collect\n",
    "    prediction = regr.predict(X.iloc[tt])\n",
    "    results.append((prediction, tt))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([26090.41373694, 32771.4900867 , 37464.48907847, ...,\n",
       "         43802.65395639, 24218.35938366, 31501.96271763]),\n",
       "  array([   0,    1,    2, ..., 5742, 5743, 5744])),\n",
       " (array([29182.5582667 , 35430.78617788, 24366.14678141, ...,\n",
       "         24644.03153976, 38003.73955572, 27719.02107049]),\n",
       "  array([ 5745,  5746,  5747, ..., 11487, 11488, 11489])),\n",
       " (array([23267.78191105, 28121.69310409, 23824.31053918, ...,\n",
       "         21776.22529139, 22975.45405445, 20295.71675193]),\n",
       "  array([11490, 11491, 11492, ..., 17232, 17233, 17234])),\n",
       " (array([26570.90847337, 22173.89261006, 20923.25014875, ...,\n",
       "         30649.37650744, 33989.92145773, 33996.51590757]),\n",
       "  array([17235, 17236, 17237, ..., 22977, 22978, 22979])),\n",
       " (array([33153.61094502, 35201.21304182, 28774.40481362, ...,\n",
       "         30143.85132357, 27332.19654725, 36125.00257214]),\n",
       "  array([22980, 22981, 22982, ..., 28721, 28722, 28723])),\n",
       " (array([29777.83069667, 38554.85484638, 37740.89693222, ...,\n",
       "         31277.13969086, 27317.26540194, 30469.65398516]),\n",
       "  array([28724, 28725, 28726, ..., 34465, 34466, 34467])),\n",
       " (array([35980.51926544, 32002.11920954, 35804.26215922, ...,\n",
       "         30862.74482248, 28078.75575971, 31230.54685006]),\n",
       "  array([34468, 34469, 34470, ..., 40209, 40210, 40211])),\n",
       " (array([29336.41480256, 31115.41931526, 34483.54981025, ...,\n",
       "         24405.69878322, 24970.74734987, 35133.95425809]),\n",
       "  array([40212, 40213, 40214, ..., 45953, 45954, 45955])),\n",
       " (array([32063.61628159, 36940.47830158, 40966.81476976, ...,\n",
       "         31760.05897975, 25360.61828235, 37294.56671866]),\n",
       "  array([45956, 45957, 45958, ..., 51697, 51698, 51699])),\n",
       " (array([32263.71783253, 25823.4357588 , 37177.32182472, ...,\n",
       "         31095.62022907, 34307.42467589, 31710.58430247]),\n",
       "  array([51700, 51701, 51702, ..., 57441, 57442, 57443]))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "#X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "#y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=2)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)\n",
    "KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "for train_index, test_index in kf.split(X):\n",
    "     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "     X_train, X_test = X[train_index], X[test_index]\n",
    "     y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:int(X.shape[0]*0.7)]\n",
    "X_test = X[int(X.shape[0]*0.7):]\n",
    "y_train = y[:int(X.shape[0]*0.7)]\n",
    "y_test = y[int(X.shape[0]*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "i = 1\n",
    "score = []\n",
    "for tr_index, val_index in tscv.split(X_train):\n",
    "    X_tr, X_val = X_train.iloc[tr_index], X_train.iloc[val_index]\n",
    "    y_tr, y_val = y_train.iloc[tr_index], y_train.iloc[val_index]\n",
    "    for mf in np.linspace(100, 150, 6):\n",
    "        for ne in np.linspace(50, 100, 6):\n",
    "            for md in np.linspace(20, 40, 5):\n",
    "                for msl in np.linspace(30, 100, 8):\n",
    "                    rfr = RandomForestRegressor(\n",
    "                        max_features=None,\n",
    "                        n_estimators=int(ne),\n",
    "                        max_depth=int(md),\n",
    "                        min_samples_leaf=int(msl))\n",
    "                    rfr.fit(X_tr, y_tr)\n",
    "                    score.append([i,\n",
    "                                  mf, \n",
    "                                  ne,\n",
    "                                  md, \n",
    "                                  msl, \n",
    "                                  rfr.score(X_val, y_val)])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10, 15, 18],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5, 7, 9],\n",
    "        'learning_rate': [0.00001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.5],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier( n_estimators=200, random_state = 42)\n",
    "XGB_random = RandomizedSearchCV(estimator = xgb, param_distributions = params, n_iter = 250, cv = 5,\n",
    "                                verbose=2, random_state=42, n_jobs = -1)\n",
    "XGB_random.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ef0a16909561>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgbr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgbr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n\u001b[0;32m      4\u001b[0m        \u001b[0mcolsample_bynode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m        \u001b[0mimportance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gain'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_delta_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "xgbr = xgb.XGBRegressor(verbosity=0) \n",
    "print(xgbr)\n",
    "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:44:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from yellowbrick.regressor import residuals_plot\n",
    "#from yellowbrick.regressor import prediction_error\n",
    "\n",
    "data = load_boston() # Loading the data\n",
    "\n",
    "#X = pd.DataFrame(data.data, columns=data.feature_names) # Feature matrix in pd.DataFrame format\n",
    "#y = pd.Series(data.target) # Target vector in pd.Series format\n",
    "\n",
    "# Making train and test sets for both X and y\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    #random_state=42, shuffle=True)\n",
    "\n",
    "# Instantiate an XGBoost object with hyperparameters\n",
    "xgb_reg = xgb.XGBRegressor(max_depth=3, n_estimators=100, n_jobs=2, objective='reg:squarederror', booster='gbtree', random_state=42, learning_rate=0.05, verbose=3)\n",
    "\n",
    "# Train the model with train data sets\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_reg.predict(X_test) # Predictions\n",
    "y_true = y_test # True values\n",
    "\n",
    "MSE = mse(y_true, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "R_squared = r2_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
